\section{Theoretical Framework}
\label{sec:theoretical-framework}

The purpose of this theoretical framework is to introduce the key concepts that allow us
to address the problem of wildfire detection using image analysis with \textit{deep
learning} techniques.
We will explore the capabilities of neural networks, specifically convolutional neural networks (CNN),
as tools for the detection and mitigation of these events.

\subsection{Convolutional Neural Networks}
\label{subsec:cnn}

Convolutional neural networks (CNNs) are a type of deep learning architecture highly
effective for processing data that can be represented as a grid, such as images.
Their design allows them to automatically learn spatial hierarchies and relevant patterns,
making them ideal for image classification and object detection tasks.

Their architecture generally consists of three main types of layers: convolutional layers,
pooling layers, and fully connected layers.
Convolutional layers apply filters to the input image to extract relevant features,
while pooling layers reduce the dimensionality of the extracted features.
Finally, fully connected layers handle the final classification, ensuring each output neuron
is connected to all neurons in the previous layer.

Using CNNs for smoke detection in wildfires has become crucial thanks to their capacity
to process large volumes of visual data, such as satellite images and surveillance camera
feeds.
This allows differentiating smoke from elements like clouds or fog, and does so
more efficiently than traditional methods.

\subsection{Xception (Extreme Inception)}
\label{subsec:xception}

Xception is an architecture based on Inception that replaces standard convolutions with
\textit{depthwise separable convolutions}, reducing the number of parameters without
affecting performance.
It splits the feature extraction into two stages: first, it filters
by channel and then mixes information across channels.
This enables more efficient learning and has shown better performance than
InceptionV3 on large datasets, although its implementation can be more computationally expensive in some cases
\cite{sathishkumar_forest_2023}.

\subsection{DenseNet}
\label{subsec:densenet}

DenseNet optimizes the flow of information by connecting each layer to all previous ones,
promoting feature reuse and improving gradient propagation.
Thanks to this structure, it manages to reduce the number of parameters compared to other deep architectures without
losing accuracy.
It is useful for very deep models, but its large number of connections can increase memory consumption during training.

\subsection{ResNet}
\label{subsec:resnet}

ResNet introduces \textit{skip connections} or residual connections that allow gradients
to pass through several layers without vanishing, solving the vanishing gradient problem
in deep networks.
Instead of learning complete transformations, it learns the differences between the input
and the expected output, making training easier and allowing networks with hundreds of layers.
Although it is highly efficient, deeper versions may require careful tuning of hyperparameters
to avoid excessive computational overhead \cite{sathishkumar_forest_2023}.

\subsection{YOLO}
\label{subsec:yolo}

You Only Look Once is an advanced object detection model designed to identify and locate
elements in images in real time with high accuracy.
Its operation is based on convolutional neural networks (CNNs) to analyze images
with a single forward pass, dividing them into grids and predicting the position,
dimensions, and class of the detected objects \cite{yaseen2024yolov8indepthexplorationinternal}.

YOLOv8, the latest version, introduces an \textit{anchor-free} approach, removing the
predefined bounding box positions used in previous versions.
This helps simplify training and improve accuracy in detecting objects of varying shapes and sizes.
It also incorporates CSPNet (\textit{Cross-Stage Partial Networks}) as a backbone, an architecture that optimizes
the flow of information and reuses features from earlier layers to reduce redundancies
and improve computational efficiency.

These characteristics make YOLOv8 highly effective for real-time tasks and for surveillance
and environmental monitoring, such as wildfire detection \cite{s23208374}.

\subsection{Transfer Learning}
\label{subsec:transfer-learning}

Transfer learning is a machine learning technique that involves reusing knowledge learned
in one domain to improve performance in another related domain.
In the context of neural networks, this involves taking a network pretrained on a large dataset and adapting it
to a smaller, more specific dataset.
