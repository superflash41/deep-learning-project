\section{Baseline}
\label{sec:baseline}

Our model is based on the work carried out by Palaparthi and Nangi in the FireSight project
at Stanford, which proposes a binary classification approach for detecting wildfires in
aerial images captured by drones.
In their study, the authors compare the performance of
deep convolutional neural networks (CNN) with Transformer-based models, implementing data
augmentation techniques and ensemble strategies to improve model accuracy.

We take FireSight's architecture as the baseline; it achieves 82.28\% accuracy through
an ensemble of CNN models (DenseNet and ResNet) and Transformers (ViT). The Stanford model
evaluates different strategies for combining features and probabilities to better
distinguish between fire and non-fire images.
It also explores model compression for possible deployment on devices with limited resources, such as UAVs.

Since the CNNs used in FireSight did not match the performance of Transformers in wildfire
detection, our work focuses on improving CNN model results through an optimized ensemble
of Xception, DenseNet, and ResNet.

Moreover, once we obtain the best ensemble model, we will apply knowledge distillation with
MobileNetV3, aiming to reduce the model size without losing accuracy, for a potential
implementation in real-time detection systems.
